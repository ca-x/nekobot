# æ·»åŠ è‡ªå®šä¹‰ API ç«¯ç‚¹

NekoBot æ”¯æŒä»»ä½• **OpenAI å…¼å®¹** çš„ API ç«¯ç‚¹ã€‚åªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  provider é…ç½®å³å¯ã€‚

## å¿«é€Ÿå¼€å§‹

### 1. åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  Provider

ç¼–è¾‘ `~/.nekobot/config.json`ï¼š

```json
{
  "providers": {
    "custom": {
      "api_key": "your-api-key",
      "api_base": "https://your-api.com/v1"
    }
  }
}
```

### 2. ä½¿ç”¨è‡ªå®šä¹‰ Provider

```bash
# æ–¹å¼ 1: é…ç½®æ–‡ä»¶æŒ‡å®šé»˜è®¤ provider
{
  "agents": {
    "defaults": {
      "provider": "custom",
      "model": "your-model-name"
    }
  }
}

# æ–¹å¼ 2: å‘½ä»¤è¡Œè¦†ç›–
nekobot agent --provider custom --model your-model-name -m "Hello"

# æ–¹å¼ 3: ç¯å¢ƒå˜é‡
export NEKOBOT_AGENTS_DEFAULTS_PROVIDER=custom
export NEKOBOT_AGENTS_DEFAULTS_MODEL=your-model-name
nekobot agent
```

---

## æ”¯æŒçš„æœåŠ¡

### 1. OpenRouter (å¤šæ¨¡å‹èšåˆ)

```json
{
  "providers": {
    "openrouter": {
      "api_key": "sk-or-v1-xxx",
      "api_base": "https://openrouter.ai/api/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "openrouter",
      "model": "anthropic/claude-3.5-sonnet"
    }
  }
}
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `anthropic/claude-3.5-sonnet`
- `openai/gpt-4-turbo`
- `google/gemini-pro`
- `meta-llama/llama-3-70b`
- æ›´å¤šæ¨¡å‹è§ [openrouter.ai/models](https://openrouter.ai/models)

---

### 2. DeepSeek (é«˜æ€§ä»·æ¯”)

```json
{
  "providers": {
    "deepseek": {
      "api_key": "sk-xxx",
      "api_base": "https://api.deepseek.com/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "deepseek",
      "model": "deepseek-chat"
    }
  }
}
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `deepseek-chat` - é€šç”¨å¯¹è¯
- `deepseek-coder` - ä»£ç ç”Ÿæˆ

---

### 3. Together AI

```json
{
  "providers": {
    "together": {
      "api_key": "xxx",
      "api_base": "https://api.together.xyz/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "together",
      "model": "meta-llama/Llama-3-70b-chat-hf"
    }
  }
}
```

---

### 4. Groq (è¶…å¿«æ¨ç†)

```json
{
  "providers": {
    "groq": {
      "api_key": "gsk_xxx",
      "api_base": "https://api.groq.com/openai/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "groq",
      "model": "llama-3.1-70b-versatile"
    }
  }
}
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `llama-3.1-70b-versatile`
- `mixtral-8x7b-32768`
- `gemma-7b-it`

---

### 5. Ollama (æœ¬åœ°éƒ¨ç½²)

```json
{
  "providers": {
    "ollama": {
      "api_key": "ollama",
      "api_base": "http://localhost:11434/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "ollama",
      "model": "llama3:70b"
    }
  }
}
```

**å®‰è£…å’Œè¿è¡Œ**ï¼š
```bash
# å®‰è£… Ollama
curl -fsSL https://ollama.com/install.sh | sh

# æ‹‰å–æ¨¡å‹
ollama pull llama3:70b

# å¯åŠ¨ API æœåŠ¡ (è‡ªåŠ¨)
# Ollama é»˜è®¤åœ¨ localhost:11434 æä¾› OpenAI å…¼å®¹ API
```

**å¯ç”¨æ¨¡å‹**ï¼š
- `llama3:70b`, `llama3:8b`
- `mistral`, `mixtral`
- `codellama`, `deepseek-coder`
- `qwen2`

---

### 6. LM Studio (æœ¬åœ° GUI)

```json
{
  "providers": {
    "lmstudio": {
      "api_key": "lm-studio",
      "api_base": "http://localhost:1234/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "lmstudio",
      "model": "local-model"
    }
  }
}
```

**ä½¿ç”¨æ­¥éª¤**ï¼š
1. ä¸‹è½½ [LM Studio](https://lmstudio.ai/)
2. åœ¨ LM Studio ä¸­ä¸‹è½½æ¨¡å‹
3. ç‚¹å‡» "Start Server" å¯åŠ¨ API
4. é»˜è®¤ç«¯å£: `localhost:1234`

---

### 7. vLLM (é«˜æ€§èƒ½è‡ªå»º)

```json
{
  "providers": {
    "vllm": {
      "api_key": "vllm",
      "api_base": "http://localhost:8000/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "vllm",
      "model": "meta-llama/Llama-3-70b-chat-hf"
    }
  }
}
```

**éƒ¨ç½² vLLM**ï¼š
```bash
# å®‰è£… vLLM
pip install vllm

# å¯åŠ¨æœåŠ¡
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Llama-3-70b-chat-hf \
  --port 8000
```

---

### 8. Azure OpenAI

```json
{
  "providers": {
    "azure": {
      "api_key": "xxx",
      "api_base": "https://<resource-name>.openai.azure.com/openai/deployments/<deployment-name>"
    }
  },
  "agents": {
    "defaults": {
      "provider": "azure",
      "model": "gpt-4"
    }
  }
}
```

---

## å¤š Provider é…ç½®

å¯ä»¥åŒæ—¶é…ç½®å¤šä¸ª providerï¼Œå¹¶æ ¹æ®éœ€è¦åˆ‡æ¢ï¼š

```json
{
  "providers": {
    "claude": {
      "api_key": "sk-ant-xxx",
      "api_base": "https://api.anthropic.com"
    },
    "openai": {
      "api_key": "sk-xxx",
      "api_base": "https://api.openai.com/v1"
    },
    "ollama": {
      "api_key": "ollama",
      "api_base": "http://localhost:11434/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "claude",
      "model": "claude-3-5-sonnet-20241022"
    }
  }
}
```

**åŠ¨æ€åˆ‡æ¢**ï¼š
```bash
# ä½¿ç”¨ Claude
nekobot agent -m "Hello"

# ä½¿ç”¨ OpenAI
nekobot agent --provider openai --model gpt-4 -m "Hello"

# ä½¿ç”¨æœ¬åœ° Ollama
nekobot agent --provider ollama --model llama3:70b -m "Hello"
```

---

## API Failover å’Œè´Ÿè½½å‡è¡¡

### 1. Profile Rotation (API Key è½®æ¢)

```json
{
  "providers": {
    "openai": {
      "api_key": "",
      "api_base": "https://api.openai.com/v1",
      "rotation": {
        "enabled": true,
        "strategy": "round_robin",
        "cooldown": "5m"
      },
      "profiles": {
        "account1": {
          "api_key": "sk-xxx-1",
          "priority": 1
        },
        "account2": {
          "api_key": "sk-xxx-2",
          "priority": 2
        },
        "backup": {
          "api_key": "sk-xxx-3",
          "priority": 3
        }
      }
    }
  }
}
```

**Rotation ç­–ç•¥**ï¼š
- `round_robin`: è½®æµä½¿ç”¨
- `least_used`: ä¼˜å…ˆä½¿ç”¨è°ƒç”¨æ¬¡æ•°æœ€å°‘çš„
- `random`: éšæœºé€‰æ‹©

### 2. å¤š Provider Fallback

åœ¨ä»£ç ä¸­å®ç°ï¼š
```go
providers := []string{"openai", "claude", "ollama"}
for _, provider := range providers {
    response, err := agent.ChatWithProvider(ctx, provider, message)
    if err == nil {
        return response
    }
}
```

---

## ç¯å¢ƒå˜é‡é…ç½®

æ‰€æœ‰é…ç½®é¡¹éƒ½å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼š

```bash
# Provider é…ç½®
export NEKOBOT_PROVIDERS_CUSTOM_API_KEY="your-key"
export NEKOBOT_PROVIDERS_CUSTOM_API_BASE="https://api.example.com/v1"

# Agent é»˜è®¤é…ç½®
export NEKOBOT_AGENTS_DEFAULTS_PROVIDER="custom"
export NEKOBOT_AGENTS_DEFAULTS_MODEL="custom-model"

# å¯åŠ¨
nekobot agent
```

---

## è‡ªå®šä¹‰ç«¯ç‚¹è¦æ±‚

NekoBot æ”¯æŒä»»ä½•éµå¾ª **OpenAI API æ ¼å¼** çš„ç«¯ç‚¹ã€‚

### å¿…éœ€çš„ API ç«¯ç‚¹

```
POST /v1/chat/completions
```

### è¯·æ±‚æ ¼å¼

```json
{
  "model": "model-name",
  "messages": [
    {"role": "user", "content": "Hello"}
  ],
  "stream": false,
  "temperature": 0.7,
  "max_tokens": 4096
}
```

### å“åº”æ ¼å¼

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "model-name",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

### Streaming æ”¯æŒ

```
POST /v1/chat/completions
Content-Type: application/json

{"model": "...", "messages": [...], "stream": true}
```

SSE æ ¼å¼å“åº”ï¼š
```
data: {"choices":[{"delta":{"content":"Hello"}}]}

data: {"choices":[{"delta":{"content":" world"}}]}

data: [DONE]
```

---

## æµ‹è¯•è‡ªå®šä¹‰ç«¯ç‚¹

```bash
# æµ‹è¯•è¿æ¥
curl -X POST https://your-api.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "your-model",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# ä½¿ç”¨ NekoBot æµ‹è¯•
nekobot agent \
  --provider custom \
  --model your-model \
  -m "Hello, test message"
```

---

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•æ·»åŠ ä¸å…¼å®¹ OpenAI æ ¼å¼çš„ APIï¼Ÿ

A: éœ€è¦åˆ›å»ºè‡ªå®šä¹‰ Adaptorã€‚å‚è€ƒ `pkg/providers/adaptors/claude/` å®ç°ã€‚

### Q: æ”¯æŒ API ä»£ç†å—ï¼Ÿ

A: æ”¯æŒã€‚åœ¨ `api_base` ä¸­é…ç½®ä»£ç†åœ°å€å³å¯ï¼š
```json
{
  "api_base": "http://proxy.example.com:8080/v1"
}
```

### Q: å¦‚ä½•ä½¿ç”¨å¤šä¸ª Ollama å®ä¾‹ï¼Ÿ

A: é…ç½®ä¸åŒåç§°çš„ providerï¼š
```json
{
  "providers": {
    "ollama-server1": {
      "api_key": "ollama",
      "api_base": "http://server1:11434/v1"
    },
    "ollama-server2": {
      "api_key": "ollama",
      "api_base": "http://server2:11434/v1"
    }
  }
}
```

### Q: æœ¬åœ°æ¨¡å‹æ€§èƒ½ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

A: è€ƒè™‘ï¼š
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (7B vs 70B)
2. å¯ç”¨é‡åŒ– (Q4, Q5)
3. ä½¿ç”¨ vLLM æé«˜ååé‡
4. ä½¿ç”¨ GPU åŠ é€Ÿ

---

## æ¨èé…ç½®

### ç”Ÿäº§ç¯å¢ƒ

```json
{
  "providers": {
    "claude": {
      "api_key": "sk-ant-xxx",
      "api_base": "https://api.anthropic.com",
      "rotation": {
        "enabled": true,
        "strategy": "least_used",
        "profiles": {
          "prod1": {"api_key": "sk-ant-1", "priority": 1},
          "prod2": {"api_key": "sk-ant-2", "priority": 2}
        }
      }
    },
    "openai-backup": {
      "api_key": "sk-xxx",
      "api_base": "https://api.openai.com/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "claude",
      "model": "claude-3-5-sonnet-20241022"
    }
  }
}
```

### å¼€å‘ç¯å¢ƒ

```json
{
  "providers": {
    "ollama": {
      "api_key": "ollama",
      "api_base": "http://localhost:11434/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "ollama",
      "model": "llama3:8b"
    }
  }
}
```

### æˆæœ¬ä¼˜åŒ–

```json
{
  "providers": {
    "deepseek": {
      "api_key": "sk-xxx",
      "api_base": "https://api.deepseek.com/v1"
    }
  },
  "agents": {
    "defaults": {
      "provider": "deepseek",
      "model": "deepseek-chat"
    }
  }
}
```

---

ç°åœ¨ä½ å¯ä»¥è¿æ¥åˆ°ä»»ä½• OpenAI å…¼å®¹çš„ API ç«¯ç‚¹äº†ï¼ğŸš€
